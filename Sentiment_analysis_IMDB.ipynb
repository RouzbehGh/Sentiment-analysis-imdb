{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sentiment_analysis_IMDB.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "p1KEBCULH-fQ",
        "colab_type": "code",
        "outputId": "794a5d53-d94e-4057-8e6b-19f60c95f30e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83
        }
      },
      "source": [
        "from __future__ import division, print_function\n",
        "from gensim import models\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.layers import Dense, Dropout, Reshape, Flatten, concatenate, Input, Conv1D, GlobalMaxPooling1D, Embedding\n",
        "from keras.layers.recurrent import LSTM\n",
        "from keras.models import Sequential\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Model\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import collections\n",
        "import re\n",
        "import string"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-zYSc_b3IKfe",
        "colab_type": "code",
        "outputId": "7163f7b3-4dba-4306-8888-14d34ece0b33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mntoivHDIVjh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = pd.read_csv('/content/drive/My Drive/Reviews.txt', delimiter='\\t')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SeXeACC_qDEi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data.columns = ['Text','Label']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Om81yjmIdze",
        "colab_type": "code",
        "outputId": "e0f06ee4-5cb5-4977-d4d9-00a2c97e7ce9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Not sure who was more lost - the flat characte...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Attempting artiness with black &amp; white and cle...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Very little music or anything to speak of.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>The best scene in the movie was when Gerardo i...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The rest of the movie lacks art, charm, meanin...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Text  Label\n",
              "0  Not sure who was more lost - the flat characte...      0\n",
              "1  Attempting artiness with black & white and cle...      0\n",
              "2       Very little music or anything to speak of.        0\n",
              "3  The best scene in the movie was when Gerardo i...      1\n",
              "4  The rest of the movie lacks art, charm, meanin...      0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DuEH92lDstuz",
        "colab_type": "code",
        "outputId": "ef54c27e-80c5-43f2-fe3a-806d02e2a4d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "data.Label.unique()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3syNgap7I4_j",
        "colab_type": "code",
        "outputId": "73495080-5c8f-43b8-9968-e04fd427599f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "data.shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(747, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJR55WHJJ2jO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pos = []\n",
        "neg = []\n",
        "for l in data.Label:\n",
        "    if l == 0 :\n",
        "        pos.append(0)\n",
        "        neg.append(1)\n",
        "    elif l == 1:\n",
        "        pos.append(1)\n",
        "        neg.append(0)          "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VXnXlbt4KF99",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data['Pos']= pos\n",
        "data['Neg']= neg"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z0vk6KZaS4ph",
        "colab_type": "code",
        "outputId": "e7d1f0b4-ca47-4c5f-be3b-c2686172e1a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Label</th>\n",
              "      <th>Pos</th>\n",
              "      <th>Neg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Not sure who was more lost - the flat characte...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Attempting artiness with black &amp; white and cle...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Very little music or anything to speak of.</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>The best scene in the movie was when Gerardo i...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The rest of the movie lacks art, charm, meanin...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Text  Label  Pos  Neg\n",
              "0  Not sure who was more lost - the flat characte...      0    0    1\n",
              "1  Attempting artiness with black & white and cle...      0    0    1\n",
              "2       Very little music or anything to speak of.        0    0    1\n",
              "3  The best scene in the movie was when Gerardo i...      1    1    0\n",
              "4  The rest of the movie lacks art, charm, meanin...      0    0    1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HpChUzDTS8FY",
        "colab_type": "code",
        "outputId": "e1f422cf-2e13-4dee-ac85-cf6a8bc0dca8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "data.tail()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Label</th>\n",
              "      <th>Pos</th>\n",
              "      <th>Neg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>742</th>\n",
              "      <td>I just got bored watching Jessice Lange take h...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>743</th>\n",
              "      <td>Unfortunately, any virtue in this film's produ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>744</th>\n",
              "      <td>In a word, it is embarrassing.</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>745</th>\n",
              "      <td>Exceptionally bad!</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>746</th>\n",
              "      <td>All in all its an insult to one's intelligence...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  Text  Label  Pos  Neg\n",
              "742  I just got bored watching Jessice Lange take h...      0    0    1\n",
              "743  Unfortunately, any virtue in this film's produ...      0    0    1\n",
              "744                   In a word, it is embarrassing.        0    0    1\n",
              "745                               Exceptionally bad!        0    0    1\n",
              "746  All in all its an insult to one's intelligence...      0    0    1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8HXRoXEDS78h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def remove_punct(text):\n",
        "    text_nopunct = ''\n",
        "    text_nopunct = re.sub('['+string.punctuation+']', '', text)\n",
        "    return text_nopunct\n",
        "\n",
        "data['Text_Clean'] = data['Text'].apply(lambda x: remove_punct(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fwbQpaDAs2pg",
        "colab_type": "code",
        "outputId": "5132b8dd-bdb4-491d-bd3c-6e1d1f58ede2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gxnehNk-TRmL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk import word_tokenize, WordNetLemmatizer\n",
        "tokens = [word_tokenize(sen) for sen in data.Text_Clean]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OxE3WEPMTRgo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def lower_token(tokens): \n",
        "    return [w.lower() for w in tokens]    \n",
        "    \n",
        "lower_tokens = [lower_token(token) for token in tokens]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVtcommMs0I-",
        "colab_type": "code",
        "outputId": "a5c148ea-5f4d-474f-b9ff-d20ff6c32c9c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pW4M8k2dTlXn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "stoplist = stopwords.words('english')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hCw8R2QMTtLq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def remove_stop_words(tokens): \n",
        "    return [word for word in tokens if word not in stoplist]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jb_Nd9Y_Twcr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filtered_words = [remove_stop_words(sen) for sen in lower_tokens]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uTiCIjE4TyLN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "result = [' '.join(sen) for sen in filtered_words]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_Mnk8zXTzo9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data['Text_Final'] = result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hwj3dNy9T0ob",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data['tokens'] = filtered_words"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MSyomH79T2MR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = data[['Text_Final', 'tokens', 'Label', 'Pos', 'Neg']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OF4EY2mnT3-b",
        "colab_type": "code",
        "outputId": "e8730906-e53c-4ff7-96e4-d7d45270767e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        }
      },
      "source": [
        "data[:10]"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text_Final</th>\n",
              "      <th>tokens</th>\n",
              "      <th>Label</th>\n",
              "      <th>Pos</th>\n",
              "      <th>Neg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>sure lost flat characters audience nearly half...</td>\n",
              "      <td>[sure, lost, flat, characters, audience, nearl...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>attempting artiness black white clever camera ...</td>\n",
              "      <td>[attempting, artiness, black, white, clever, c...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>little music anything speak</td>\n",
              "      <td>[little, music, anything, speak]</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>best scene movie gerardo trying find song keep...</td>\n",
              "      <td>[best, scene, movie, gerardo, trying, find, so...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>rest movie lacks art charm meaning emptiness w...</td>\n",
              "      <td>[rest, movie, lacks, art, charm, meaning, empt...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>wasted two hours</td>\n",
              "      <td>[wasted, two, hours]</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>saw movie today thought good effort good messa...</td>\n",
              "      <td>[saw, movie, today, thought, good, effort, goo...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>bit predictable</td>\n",
              "      <td>[bit, predictable]</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>loved casting jimmy buffet science teacher</td>\n",
              "      <td>[loved, casting, jimmy, buffet, science, teacher]</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>baby owls adorable</td>\n",
              "      <td>[baby, owls, adorable]</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                          Text_Final  ... Neg\n",
              "0  sure lost flat characters audience nearly half...  ...   1\n",
              "1  attempting artiness black white clever camera ...  ...   1\n",
              "2                        little music anything speak  ...   1\n",
              "3  best scene movie gerardo trying find song keep...  ...   0\n",
              "4  rest movie lacks art charm meaning emptiness w...  ...   1\n",
              "5                                   wasted two hours  ...   1\n",
              "6  saw movie today thought good effort good messa...  ...   0\n",
              "7                                    bit predictable  ...   1\n",
              "8         loved casting jimmy buffet science teacher  ...   0\n",
              "9                                 baby owls adorable  ...   0\n",
              "\n",
              "[10 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W9Bwm1wBT9FT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_train, data_test = train_test_split(data, test_size=0.10, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fgYqbp03UAA7",
        "colab_type": "code",
        "outputId": "541ba360-4089-4741-a6a7-5f7fabd3f14d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "all_training_words = [word for tokens in data_train[\"tokens\"] for word in tokens]\n",
        "training_sentence_lengths = [len(tokens) for tokens in data_train[\"tokens\"]]\n",
        "TRAINING_VOCAB = sorted(list(set(all_training_words)))\n",
        "print(\"%s words total, with a vocabulary size of %s\" % (len(all_training_words), len(TRAINING_VOCAB)))\n",
        "print(\"Max sentence length is %s\" % max(training_sentence_lengths))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6968 words total, with a vocabulary size of 2824\n",
            "Max sentence length is 789\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pxfo3xvVUCdH",
        "colab_type": "code",
        "outputId": "51f72729-9e0b-4dfe-e398-a61caf895dfc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "all_test_words = [word for tokens in data_test[\"tokens\"] for word in tokens]\n",
        "test_sentence_lengths = [len(tokens) for tokens in data_test[\"tokens\"]]\n",
        "TEST_VOCAB = sorted(list(set(all_test_words)))\n",
        "print(\"%s words total, with a vocabulary size of %s\" % (len(all_test_words), len(TEST_VOCAB)))\n",
        "print(\"Max sentence length is %s\" % max(test_sentence_lengths))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "823 words total, with a vocabulary size of 584\n",
            "Max sentence length is 160\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nH8ClPZNUCUw",
        "colab_type": "code",
        "outputId": "1455f2c5-e1a4-4386-e3e3-e60318bc8eae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "source": [
        "word2vec_path = '/content/drive/My Drive/envec.txt'\n",
        "word2vec = models.KeyedVectors.load_word2vec_format(word2vec_path, binary=True)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QYKoH_myUMbx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_average_word2vec(tokens_list, vector, generate_missing=False, k=200):\n",
        "    if len(tokens_list)<1:\n",
        "        return np.zeros(k)\n",
        "    if generate_missing:\n",
        "        vectorized = [vector[word] if word in vector else np.random.rand(k) for word in tokens_list]\n",
        "    else:\n",
        "        vectorized = [vector[word] if word in vector else np.zeros(k) for word in tokens_list]\n",
        "    length = len(vectorized)\n",
        "    summed = np.sum(vectorized, axis=0)\n",
        "    averaged = np.divide(summed, length)\n",
        "    return averaged\n",
        "\n",
        "def get_word2vec_embeddings(vectors, clean_comments, generate_missing=False):\n",
        "    embeddings = clean_comments['tokens'].apply(lambda x: get_average_word2vec(x, vectors, \n",
        "                                                                                generate_missing=generate_missing))\n",
        "    return list(embeddings)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Vtg9fxbUO06",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_embeddings = get_word2vec_embeddings(word2vec, data_train, generate_missing=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q9HWbfnejxFl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_SEQUENCE_LENGTH = 50\n",
        "EMBEDDING_DIM = 200"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n4G_fMdKj03H",
        "colab_type": "code",
        "outputId": "a55f765c-a514-468e-f8e9-5b248687939b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "tokenizer = Tokenizer(num_words=len(TRAINING_VOCAB), lower=True, char_level=False)\n",
        "tokenizer.fit_on_texts(data_train[\"Text_Final\"].tolist())\n",
        "training_sequences = tokenizer.texts_to_sequences(data_train[\"Text_Final\"].tolist())\n",
        "\n",
        "train_word_index = tokenizer.word_index\n",
        "print('Found %s unique tokens.' % len(train_word_index))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2824 unique tokens.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wviOmTn4j3Qd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_cnn_data = pad_sequences(training_sequences, maxlen=MAX_SEQUENCE_LENGTH)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JSuBUuv-j541",
        "colab_type": "code",
        "outputId": "195cb426-f823-4da6-d3a8-4f377b29c0c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "train_embedding_weights = np.zeros((len(train_word_index)+1, EMBEDDING_DIM))\n",
        "for word,index in train_word_index.items():\n",
        "    train_embedding_weights[index,:] = word2vec[word] if word in word2vec else np.random.rand(EMBEDDING_DIM)\n",
        "print(train_embedding_weights.shape)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2825, 200)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8PX862tPkA-P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_sequences = tokenizer.texts_to_sequences(data_test[\"Text_Final\"].tolist())\n",
        "test_cnn_data = pad_sequences(test_sequences, maxlen=MAX_SEQUENCE_LENGTH)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6tayx3aQkDVX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def ConvNet(embeddings, max_sequence_length, num_words, embedding_dim, labels_index):\n",
        "    \n",
        "    embedding_layer = Embedding(num_words,\n",
        "                            embedding_dim,\n",
        "                            weights=[embeddings],\n",
        "                            input_length=max_sequence_length,\n",
        "                            trainable=False)\n",
        "    \n",
        "    sequence_input = Input(shape=(max_sequence_length,), dtype='int32')\n",
        "    embedded_sequences = embedding_layer(sequence_input)\n",
        "\n",
        "    convs = []\n",
        "    filter_sizes = [2,3,4,5,6]\n",
        "\n",
        "    for filter_size in filter_sizes:\n",
        "        l_conv = Conv1D(filters=200, kernel_size=filter_size, activation='relu')(embedded_sequences)\n",
        "        l_pool = GlobalMaxPooling1D()(l_conv)\n",
        "        convs.append(l_pool)\n",
        "\n",
        "\n",
        "    l_merge = concatenate(convs, axis=1)\n",
        "\n",
        "    x = Dropout(0.1)(l_merge)  \n",
        "    x = Dense(128, activation='relu')(x)\n",
        "    x = Dropout(0.2)(x)\n",
        "    preds = Dense(labels_index, activation='sigmoid')(x)\n",
        "\n",
        "    model = Model(sequence_input, preds)\n",
        "    model.compile(loss='binary_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['acc'])\n",
        "    model.summary()\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AmDqk9owkGzI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label_names = ['Pos', 'Neg']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EWiT7TSDkIfW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train = data_train[label_names].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zjNEqjk5kKZY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = train_cnn_data\n",
        "y_tr = y_train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTKFhfVNkM1V",
        "colab_type": "code",
        "outputId": "d2238018-c92c-4f5c-df80-40bf6a303f77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model = ConvNet(train_embedding_weights, MAX_SEQUENCE_LENGTH, len(train_word_index)+1, EMBEDDING_DIM, \n",
        "                len(list(label_names)))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 50)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, 50, 200)      565000      input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_1 (Conv1D)               (None, 49, 200)      80200       embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_2 (Conv1D)               (None, 48, 200)      120200      embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_3 (Conv1D)               (None, 47, 200)      160200      embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_4 (Conv1D)               (None, 46, 200)      200200      embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_5 (Conv1D)               (None, 45, 200)      240200      embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_1 (GlobalM (None, 200)          0           conv1d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_2 (GlobalM (None, 200)          0           conv1d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_3 (GlobalM (None, 200)          0           conv1d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_4 (GlobalM (None, 200)          0           conv1d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_5 (GlobalM (None, 200)          0           conv1d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 1000)         0           global_max_pooling1d_1[0][0]     \n",
            "                                                                 global_max_pooling1d_2[0][0]     \n",
            "                                                                 global_max_pooling1d_3[0][0]     \n",
            "                                                                 global_max_pooling1d_4[0][0]     \n",
            "                                                                 global_max_pooling1d_5[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 1000)         0           concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 128)          128128      dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 128)          0           dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 2)            258         dropout_2[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 1,494,386\n",
            "Trainable params: 929,386\n",
            "Non-trainable params: 565,000\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WYHkt3h9kQ8n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_epochs = 100\n",
        "batch_size = 34"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EvcdwpxqkTNO",
        "colab_type": "code",
        "outputId": "3e94cb74-5c22-426a-8367-93e38e3e879c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "hist = model.fit(x_train, y_tr, epochs=num_epochs, validation_split=0.1, shuffle=True, batch_size=batch_size)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Train on 604 samples, validate on 68 samples\n",
            "Epoch 1/100\n",
            "604/604 [==============================] - 7s 12ms/step - loss: 0.9672 - acc: 0.5124 - val_loss: 0.6946 - val_acc: 0.5074\n",
            "Epoch 2/100\n",
            "604/604 [==============================] - 0s 224us/step - loss: 0.8242 - acc: 0.5629 - val_loss: 0.6788 - val_acc: 0.5588\n",
            "Epoch 3/100\n",
            "604/604 [==============================] - 0s 210us/step - loss: 0.8231 - acc: 0.5844 - val_loss: 0.7281 - val_acc: 0.4412\n",
            "Epoch 4/100\n",
            "604/604 [==============================] - 0s 221us/step - loss: 0.7821 - acc: 0.5935 - val_loss: 0.6808 - val_acc: 0.5662\n",
            "Epoch 5/100\n",
            "604/604 [==============================] - 0s 206us/step - loss: 0.7987 - acc: 0.6391 - val_loss: 0.6586 - val_acc: 0.6985\n",
            "Epoch 6/100\n",
            "604/604 [==============================] - 0s 225us/step - loss: 0.7317 - acc: 0.6879 - val_loss: 0.6936 - val_acc: 0.4779\n",
            "Epoch 7/100\n",
            "604/604 [==============================] - 0s 234us/step - loss: 0.6925 - acc: 0.7219 - val_loss: 0.6459 - val_acc: 0.6618\n",
            "Epoch 8/100\n",
            "604/604 [==============================] - 0s 210us/step - loss: 0.6476 - acc: 0.7252 - val_loss: 0.7605 - val_acc: 0.5735\n",
            "Epoch 9/100\n",
            "604/604 [==============================] - 0s 216us/step - loss: 0.5832 - acc: 0.8278 - val_loss: 0.6167 - val_acc: 0.6397\n",
            "Epoch 10/100\n",
            "604/604 [==============================] - 0s 221us/step - loss: 0.4966 - acc: 0.8775 - val_loss: 0.6731 - val_acc: 0.6176\n",
            "Epoch 11/100\n",
            "604/604 [==============================] - 0s 212us/step - loss: 0.4161 - acc: 0.9156 - val_loss: 0.5993 - val_acc: 0.6471\n",
            "Epoch 12/100\n",
            "604/604 [==============================] - 0s 207us/step - loss: 0.4025 - acc: 0.8825 - val_loss: 0.6670 - val_acc: 0.6471\n",
            "Epoch 13/100\n",
            "604/604 [==============================] - 0s 207us/step - loss: 0.2855 - acc: 0.9470 - val_loss: 0.6838 - val_acc: 0.6912\n",
            "Epoch 14/100\n",
            "604/604 [==============================] - 0s 216us/step - loss: 0.3107 - acc: 0.9305 - val_loss: 0.7112 - val_acc: 0.6912\n",
            "Epoch 15/100\n",
            "604/604 [==============================] - 0s 214us/step - loss: 0.3160 - acc: 0.9272 - val_loss: 0.9916 - val_acc: 0.6176\n",
            "Epoch 16/100\n",
            "604/604 [==============================] - 0s 212us/step - loss: 0.2451 - acc: 0.9652 - val_loss: 0.6558 - val_acc: 0.6618\n",
            "Epoch 17/100\n",
            "604/604 [==============================] - 0s 227us/step - loss: 0.2123 - acc: 0.9768 - val_loss: 0.8880 - val_acc: 0.7059\n",
            "Epoch 18/100\n",
            "604/604 [==============================] - 0s 231us/step - loss: 0.1899 - acc: 0.9843 - val_loss: 0.6873 - val_acc: 0.6544\n",
            "Epoch 19/100\n",
            "604/604 [==============================] - 0s 206us/step - loss: 0.1773 - acc: 0.9884 - val_loss: 0.7555 - val_acc: 0.7206\n",
            "Epoch 20/100\n",
            "604/604 [==============================] - 0s 209us/step - loss: 0.1894 - acc: 0.9892 - val_loss: 0.8114 - val_acc: 0.6912\n",
            "Epoch 21/100\n",
            "604/604 [==============================] - 0s 212us/step - loss: 0.1620 - acc: 0.9901 - val_loss: 0.8810 - val_acc: 0.6985\n",
            "Epoch 22/100\n",
            "604/604 [==============================] - 0s 269us/step - loss: 0.1521 - acc: 0.9917 - val_loss: 0.9200 - val_acc: 0.6912\n",
            "Epoch 23/100\n",
            "604/604 [==============================] - 0s 210us/step - loss: 0.1499 - acc: 0.9909 - val_loss: 0.7869 - val_acc: 0.7059\n",
            "Epoch 24/100\n",
            "604/604 [==============================] - 0s 210us/step - loss: 0.1735 - acc: 0.9901 - val_loss: 0.8339 - val_acc: 0.7059\n",
            "Epoch 25/100\n",
            "604/604 [==============================] - 0s 215us/step - loss: 0.1467 - acc: 0.9909 - val_loss: 1.0507 - val_acc: 0.6765\n",
            "Epoch 26/100\n",
            "604/604 [==============================] - 0s 258us/step - loss: 0.1445 - acc: 0.9909 - val_loss: 0.9339 - val_acc: 0.6985\n",
            "Epoch 27/100\n",
            "604/604 [==============================] - 0s 247us/step - loss: 0.1738 - acc: 0.9876 - val_loss: 1.2855 - val_acc: 0.6176\n",
            "Epoch 28/100\n",
            "604/604 [==============================] - 0s 221us/step - loss: 0.5199 - acc: 0.8469 - val_loss: 0.6244 - val_acc: 0.7132\n",
            "Epoch 29/100\n",
            "604/604 [==============================] - 0s 216us/step - loss: 0.4803 - acc: 0.8146 - val_loss: 0.7808 - val_acc: 0.5882\n",
            "Epoch 30/100\n",
            "604/604 [==============================] - 0s 226us/step - loss: 0.2431 - acc: 0.9743 - val_loss: 0.7064 - val_acc: 0.6397\n",
            "Epoch 31/100\n",
            "604/604 [==============================] - 0s 215us/step - loss: 0.1698 - acc: 0.9859 - val_loss: 0.7559 - val_acc: 0.6618\n",
            "Epoch 32/100\n",
            "604/604 [==============================] - 0s 237us/step - loss: 0.1480 - acc: 0.9917 - val_loss: 0.7838 - val_acc: 0.6471\n",
            "Epoch 33/100\n",
            "604/604 [==============================] - 0s 218us/step - loss: 0.1509 - acc: 0.9892 - val_loss: 1.0744 - val_acc: 0.6912\n",
            "Epoch 34/100\n",
            "604/604 [==============================] - 0s 228us/step - loss: 0.1299 - acc: 0.9925 - val_loss: 1.0901 - val_acc: 0.6765\n",
            "Epoch 35/100\n",
            "604/604 [==============================] - 0s 224us/step - loss: 0.1127 - acc: 0.9934 - val_loss: 1.0022 - val_acc: 0.6912\n",
            "Epoch 36/100\n",
            "604/604 [==============================] - 0s 212us/step - loss: 0.1645 - acc: 0.9901 - val_loss: 1.0397 - val_acc: 0.6912\n",
            "Epoch 37/100\n",
            "604/604 [==============================] - 0s 241us/step - loss: 0.1250 - acc: 0.9925 - val_loss: 1.0510 - val_acc: 0.6912\n",
            "Epoch 38/100\n",
            "604/604 [==============================] - 0s 209us/step - loss: 0.1364 - acc: 0.9917 - val_loss: 1.2111 - val_acc: 0.6985\n",
            "Epoch 39/100\n",
            "604/604 [==============================] - 0s 220us/step - loss: 0.1357 - acc: 0.9917 - val_loss: 1.0958 - val_acc: 0.6912\n",
            "Epoch 40/100\n",
            "604/604 [==============================] - 0s 219us/step - loss: 0.1355 - acc: 0.9917 - val_loss: 1.2058 - val_acc: 0.6985\n",
            "Epoch 41/100\n",
            "604/604 [==============================] - 0s 208us/step - loss: 0.1219 - acc: 0.9925 - val_loss: 1.1141 - val_acc: 0.6912\n",
            "Epoch 42/100\n",
            "604/604 [==============================] - 0s 226us/step - loss: 0.1481 - acc: 0.9909 - val_loss: 1.2516 - val_acc: 0.7059\n",
            "Epoch 43/100\n",
            "604/604 [==============================] - 0s 217us/step - loss: 0.1611 - acc: 0.9901 - val_loss: 1.0612 - val_acc: 0.6765\n",
            "Epoch 44/100\n",
            "604/604 [==============================] - 0s 209us/step - loss: 0.1612 - acc: 0.9901 - val_loss: 1.0367 - val_acc: 0.6985\n",
            "Epoch 45/100\n",
            "604/604 [==============================] - 0s 231us/step - loss: 0.1631 - acc: 0.9892 - val_loss: 1.0248 - val_acc: 0.6471\n",
            "Epoch 46/100\n",
            "604/604 [==============================] - 0s 216us/step - loss: 0.1615 - acc: 0.9901 - val_loss: 1.1185 - val_acc: 0.6912\n",
            "Epoch 47/100\n",
            "604/604 [==============================] - 0s 215us/step - loss: 0.1475 - acc: 0.9909 - val_loss: 1.1996 - val_acc: 0.6912\n",
            "Epoch 48/100\n",
            "604/604 [==============================] - 0s 235us/step - loss: 0.1610 - acc: 0.9901 - val_loss: 1.3322 - val_acc: 0.6765\n",
            "Epoch 49/100\n",
            "604/604 [==============================] - 0s 225us/step - loss: 0.1606 - acc: 0.9901 - val_loss: 1.2844 - val_acc: 0.6765\n",
            "Epoch 50/100\n",
            "604/604 [==============================] - 0s 208us/step - loss: 0.1603 - acc: 0.9901 - val_loss: 1.1453 - val_acc: 0.6691\n",
            "Epoch 51/100\n",
            "604/604 [==============================] - 0s 209us/step - loss: 0.1336 - acc: 0.9917 - val_loss: 1.3557 - val_acc: 0.6985\n",
            "Epoch 52/100\n",
            "604/604 [==============================] - 0s 221us/step - loss: 0.1601 - acc: 0.9901 - val_loss: 1.1383 - val_acc: 0.6912\n",
            "Epoch 53/100\n",
            "604/604 [==============================] - 0s 234us/step - loss: 0.1075 - acc: 0.9934 - val_loss: 1.2406 - val_acc: 0.6618\n",
            "Epoch 54/100\n",
            "604/604 [==============================] - 0s 215us/step - loss: 0.1468 - acc: 0.9909 - val_loss: 1.3287 - val_acc: 0.6691\n",
            "Epoch 55/100\n",
            "604/604 [==============================] - 0s 198us/step - loss: 0.1334 - acc: 0.9917 - val_loss: 1.2837 - val_acc: 0.6691\n",
            "Epoch 56/100\n",
            "604/604 [==============================] - 0s 208us/step - loss: 0.1467 - acc: 0.9909 - val_loss: 1.4087 - val_acc: 0.6838\n",
            "Epoch 57/100\n",
            "604/604 [==============================] - 0s 210us/step - loss: 0.1332 - acc: 0.9917 - val_loss: 1.2436 - val_acc: 0.6765\n",
            "Epoch 58/100\n",
            "604/604 [==============================] - 0s 232us/step - loss: 0.1332 - acc: 0.9917 - val_loss: 1.3230 - val_acc: 0.6765\n",
            "Epoch 59/100\n",
            "604/604 [==============================] - 0s 205us/step - loss: 0.1331 - acc: 0.9917 - val_loss: 1.2820 - val_acc: 0.6765\n",
            "Epoch 60/100\n",
            "604/604 [==============================] - 0s 217us/step - loss: 0.1334 - acc: 0.9917 - val_loss: 1.3650 - val_acc: 0.6765\n",
            "Epoch 61/100\n",
            "604/604 [==============================] - 0s 236us/step - loss: 0.1333 - acc: 0.9917 - val_loss: 1.3890 - val_acc: 0.6471\n",
            "Epoch 62/100\n",
            "604/604 [==============================] - 0s 221us/step - loss: 0.1332 - acc: 0.9917 - val_loss: 1.2852 - val_acc: 0.6765\n",
            "Epoch 63/100\n",
            "604/604 [==============================] - 0s 207us/step - loss: 0.1331 - acc: 0.9917 - val_loss: 1.4576 - val_acc: 0.6838\n",
            "Epoch 64/100\n",
            "604/604 [==============================] - 0s 207us/step - loss: 0.1331 - acc: 0.9917 - val_loss: 1.2739 - val_acc: 0.6765\n",
            "Epoch 65/100\n",
            "604/604 [==============================] - 0s 228us/step - loss: 0.1596 - acc: 0.9901 - val_loss: 1.4927 - val_acc: 0.6838\n",
            "Epoch 66/100\n",
            "604/604 [==============================] - 0s 218us/step - loss: 0.1595 - acc: 0.9901 - val_loss: 1.4461 - val_acc: 0.6765\n",
            "Epoch 67/100\n",
            "604/604 [==============================] - 0s 210us/step - loss: 0.1467 - acc: 0.9909 - val_loss: 1.6280 - val_acc: 0.6912\n",
            "Epoch 68/100\n",
            "604/604 [==============================] - 0s 219us/step - loss: 0.1199 - acc: 0.9925 - val_loss: 1.3761 - val_acc: 0.6912\n",
            "Epoch 69/100\n",
            "604/604 [==============================] - 0s 239us/step - loss: 0.1464 - acc: 0.9909 - val_loss: 1.5293 - val_acc: 0.6912\n",
            "Epoch 70/100\n",
            "604/604 [==============================] - 0s 238us/step - loss: 0.1595 - acc: 0.9901 - val_loss: 1.4588 - val_acc: 0.6765\n",
            "Epoch 71/100\n",
            "604/604 [==============================] - 0s 226us/step - loss: 0.1330 - acc: 0.9917 - val_loss: 1.5550 - val_acc: 0.6912\n",
            "Epoch 72/100\n",
            "604/604 [==============================] - 0s 211us/step - loss: 0.1065 - acc: 0.9934 - val_loss: 1.4403 - val_acc: 0.6912\n",
            "Epoch 73/100\n",
            "604/604 [==============================] - 0s 238us/step - loss: 0.1332 - acc: 0.9917 - val_loss: 1.3001 - val_acc: 0.6471\n",
            "Epoch 74/100\n",
            "604/604 [==============================] - 0s 213us/step - loss: 0.1472 - acc: 0.9909 - val_loss: 1.2807 - val_acc: 0.6544\n",
            "Epoch 75/100\n",
            "604/604 [==============================] - 0s 247us/step - loss: 0.1642 - acc: 0.9884 - val_loss: 1.3755 - val_acc: 0.6691\n",
            "Epoch 76/100\n",
            "604/604 [==============================] - 0s 226us/step - loss: 0.3011 - acc: 0.9272 - val_loss: 1.8808 - val_acc: 0.4706\n",
            "Epoch 77/100\n",
            "604/604 [==============================] - 0s 239us/step - loss: 0.2505 - acc: 0.9636 - val_loss: 0.8076 - val_acc: 0.6471\n",
            "Epoch 78/100\n",
            "604/604 [==============================] - 0s 212us/step - loss: 0.1502 - acc: 0.9884 - val_loss: 0.9188 - val_acc: 0.6324\n",
            "Epoch 79/100\n",
            "604/604 [==============================] - 0s 214us/step - loss: 0.1456 - acc: 0.9901 - val_loss: 1.5067 - val_acc: 0.6765\n",
            "Epoch 80/100\n",
            "604/604 [==============================] - 0s 219us/step - loss: 0.1393 - acc: 0.9917 - val_loss: 1.3332 - val_acc: 0.6912\n",
            "Epoch 81/100\n",
            "604/604 [==============================] - 0s 225us/step - loss: 0.1366 - acc: 0.9917 - val_loss: 1.0793 - val_acc: 0.6471\n",
            "Epoch 82/100\n",
            "604/604 [==============================] - 0s 214us/step - loss: 0.1368 - acc: 0.9901 - val_loss: 1.0801 - val_acc: 0.6471\n",
            "Epoch 83/100\n",
            "604/604 [==============================] - 0s 221us/step - loss: 0.1357 - acc: 0.9917 - val_loss: 1.3441 - val_acc: 0.6691\n",
            "Epoch 84/100\n",
            "604/604 [==============================] - 0s 226us/step - loss: 0.1350 - acc: 0.9917 - val_loss: 1.5785 - val_acc: 0.6765\n",
            "Epoch 85/100\n",
            "604/604 [==============================] - 0s 214us/step - loss: 0.1610 - acc: 0.9901 - val_loss: 1.4347 - val_acc: 0.6618\n",
            "Epoch 86/100\n",
            "604/604 [==============================] - 0s 208us/step - loss: 0.1342 - acc: 0.9917 - val_loss: 1.3305 - val_acc: 0.6618\n",
            "Epoch 87/100\n",
            "604/604 [==============================] - 0s 200us/step - loss: 0.1604 - acc: 0.9901 - val_loss: 1.3678 - val_acc: 0.6544\n",
            "Epoch 88/100\n",
            "604/604 [==============================] - 0s 202us/step - loss: 0.1334 - acc: 0.9917 - val_loss: 1.6335 - val_acc: 0.6912\n",
            "Epoch 89/100\n",
            "604/604 [==============================] - 0s 232us/step - loss: 0.1334 - acc: 0.9917 - val_loss: 1.3708 - val_acc: 0.6471\n",
            "Epoch 90/100\n",
            "604/604 [==============================] - 0s 210us/step - loss: 0.1333 - acc: 0.9917 - val_loss: 1.4247 - val_acc: 0.6471\n",
            "Epoch 91/100\n",
            "604/604 [==============================] - 0s 235us/step - loss: 0.1332 - acc: 0.9917 - val_loss: 1.5644 - val_acc: 0.6618\n",
            "Epoch 92/100\n",
            "604/604 [==============================] - 0s 239us/step - loss: 0.1331 - acc: 0.9917 - val_loss: 1.4720 - val_acc: 0.6691\n",
            "Epoch 93/100\n",
            "604/604 [==============================] - 0s 213us/step - loss: 0.1336 - acc: 0.9917 - val_loss: 1.3526 - val_acc: 0.6544\n",
            "Epoch 94/100\n",
            "604/604 [==============================] - 0s 207us/step - loss: 0.1471 - acc: 0.9909 - val_loss: 1.6143 - val_acc: 0.6691\n",
            "Epoch 95/100\n",
            "604/604 [==============================] - 0s 207us/step - loss: 0.1332 - acc: 0.9917 - val_loss: 1.5220 - val_acc: 0.6691\n",
            "Epoch 96/100\n",
            "604/604 [==============================] - 0s 209us/step - loss: 0.1330 - acc: 0.9917 - val_loss: 1.6790 - val_acc: 0.6691\n",
            "Epoch 97/100\n",
            "604/604 [==============================] - 0s 202us/step - loss: 0.1595 - acc: 0.9901 - val_loss: 1.6625 - val_acc: 0.6618\n",
            "Epoch 98/100\n",
            "604/604 [==============================] - 0s 230us/step - loss: 0.1596 - acc: 0.9901 - val_loss: 1.5430 - val_acc: 0.6618\n",
            "Epoch 99/100\n",
            "604/604 [==============================] - 0s 213us/step - loss: 0.1598 - acc: 0.9901 - val_loss: 1.4308 - val_acc: 0.6544\n",
            "Epoch 100/100\n",
            "604/604 [==============================] - 0s 217us/step - loss: 0.1335 - acc: 0.9917 - val_loss: 1.9550 - val_acc: 0.6765\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X1zi5D6sklT-",
        "colab_type": "code",
        "outputId": "861fa7b8-ceda-4207-a4b5-edc295421663",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "predictions = model.predict(test_cnn_data, batch_size=1024, verbose=1)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r75/75 [==============================] - 0s 3ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MP6lKdOOkoLv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels = [1, 0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gNZdmUozkrGx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prediction_labels=[]\n",
        "for p in predictions:\n",
        "    prediction_labels.append(labels[np.argmax(p)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZTeFnPk9kuhk",
        "colab_type": "code",
        "outputId": "9460a525-03d8-468f-dc54-f3a005045932",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "sum(data_test.Label==prediction_labels)/len(prediction_labels)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6666666666666666"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KfAG58NqkwgU",
        "colab_type": "code",
        "outputId": "63183325-7f72-40f1-c0dd-a7b45b65f38d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "data_test.Label.value_counts()"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    39\n",
              "1    36\n",
              "Name: Label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    }
  ]
}